# PostgreSQL Configuration
# Database connection settings for storing resources and embeddings
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=study_companion
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_password_here

# OpenAI Configuration (OPTIONAL - only needed if not using Ollama)
# Required for generating embeddings if OLLAMA_BASE_URL is not set
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# Ollama Configuration (DEFAULT - recommended for local development)
# Ollama is used by default for embeddings and chat models
# If OLLAMA_BASE_URL is set, Ollama will be used instead of OpenAI
# 
# IMPORTANT: Ollama runs locally (not in Docker) - run: ./scripts/setup-ollama-macos.sh
# 
# For local development: http://localhost:11434 (default)
# For Docker containers: http://host.docker.internal:11434
OLLAMA_BASE_URL=http://localhost:11434

# Data Directory Configuration
# Base directory for storing intermediate files (extracted text and embeddings)
# The I/O managers will use subdirectories: {DATA_DIR}/extracted_text and {DATA_DIR}/embeddings
# Defaults to ./data/extracted_text and ./data/embeddings if not set
DATA_DIR=./data
